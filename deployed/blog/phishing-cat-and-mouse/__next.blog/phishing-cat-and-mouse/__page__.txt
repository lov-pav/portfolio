1:"$Sreact.fragment"
2:I[44298,["/_next/static/chunks/ea12239a14acbc1d.js","/_next/static/chunks/cd8fa2376cd44278.js","/_next/static/chunks/e077ac6148382a55.js","/_next/static/chunks/62397d08572e7e3e.js","/_next/static/chunks/12849b5b6ea987cc.js"],"default"]
3:I[2160,["/_next/static/chunks/ea12239a14acbc1d.js","/_next/static/chunks/cd8fa2376cd44278.js","/_next/static/chunks/e077ac6148382a55.js","/_next/static/chunks/62397d08572e7e3e.js","/_next/static/chunks/12849b5b6ea987cc.js"],"default"]
6:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/7340adf74ff47ec0.js"],"OutletBoundary"]
7:"$Sreact.suspense"
0:{"buildId":"c7blrjOImPQFhtbUh_M0B","rsc":["$","$1","c",{"children":[["$","$L2",null,{"title":"When 99% Accuracy Wasn't Enough: Building VeriPhish","date":"December 23, 2025","category":"Engineering","children":[["$","p",null,{"children":["I thought I had it figured out. My phishing detection model hit ",["$","strong",null,{"children":"98.4% accuracy"}],". The confusion matrix was clean. The ROC curve was textbook perfect. Time to ship, right?"]}],["$","p",null,{"children":"Wrong. Dead wrong."}],["$","h3",null,{"children":"The User Trust Problem"}],["$","p",null,{"children":"When I tested VeriPhish with actual users, the feedback was brutal. Someone from HR opened an email my model flagged with 0.97 confidence. When I asked why, they shrugged:"}],["$","blockquote",null,{"children":"\"It said 'phishing detected' but it looked exactly like the emails we get every week. How is a number supposed to convince me?\""}],["$","p",null,{"children":["That's when it clicked: ",["$","strong",null,{"children":"in cybersecurity, explainability is just as important as accuracy"}],". A black box that says \"Trust Me\" works for Netflix recommendations. It doesn't work when you're asking someone to delete a potentially important email."]}],["$","h3",null,{"children":"The Architecture"}],["$","p",null,{"children":"I built VeriPhish with multiple interfaces to test what works best with different users. Here's the project structure I ended up with:"}],["$","pre",null,{"children":["$","code",null,{"children":"├── main.py                    # Train and evaluate models\n├── explainable_model.py       # Model with LIME/SHAP explanations\n├── enhanced_features.py       # Custom phishing indicators\n├── demo_phishing.py           # Desktop GUI application\n├── explicateGUI.py            # Advanced GUI with LLM integration\n├── app.py                     # Flask API\n└── web_app/                   # Full web interface\n    └── app.py"}]}],["$","p",null,{"children":["The model is trained on multiple phishing datasets: CEAS 2008, Enron corpus, Nigerian fraud emails, and SpamAssassin. But the real magic is in ",["$","code",null,{"children":"explainable_model.py"}],":"]}],["$","$L3",null,{"type":"phishing"}],["$","ol",null,{"children":[["$","li",null,{"children":[["$","strong",null,{"children":"Text Processing:"}]," Email text is cleaned and preprocessed"]}],["$","li",null,{"children":[["$","strong",null,{"children":"Feature Extraction:"}]," TF-IDF features + custom phishing indicators"]}],["$","li",null,{"children":[["$","strong",null,{"children":"Prediction:"}]," Logistic regression classification"]}],["$","li",null,{"children":[["$","strong",null,{"children":"Explanation:"}]," LIME and SHAP identify influential words"]}]]}],["$","h3",null,{"children":"The LLM Enhancement"}],["$","p",null,{"children":["The breakthrough came when I integrated ",["$","strong",null,{"children":"DeepSeek"}]," into ",["$","code",null,{"children":"explicateGUI.py"}],". Instead of showing raw SHAP values, the LLM translates them into plain English:"]}],["$","pre",null,{"children":["$","code",null,{"children":"\"This email was flagged because:\n• 'Urgent Action Required' in subject line (high urgency indicator)\n• Sender domain 'google-security-verify.com' doesn't match Google\n• Multiple call-to-action phrases detected in body\""}]}],["$","p",null,{"children":["Suddenly users understood ",["$","em",null,{"children":"why"}]," an email was suspicious. They started trusting the system."]}],["$","h3",null,{"children":"The Result"}],["$","p",null,{"children":["VeriPhish won ",["$","strong",null,{"children":"First Place Student Paper"}]," and ",["$","strong",null,{"children":"Second Place Order of Merit"}]," at IEEE ICCST 2025. But more importantly—users actually listen now when the system flags something."]}],["$","p",null,{"children":["The lesson? Build systems that ",["$","strong",null,{"children":"explain themselves"}],". Especially in security, where user behavior determines outcomes."]}]]}],["$L4"],"$L5"]}],"loading":null,"isPartial":false}
4:["$","script","script-0",{"src":"/_next/static/chunks/12849b5b6ea987cc.js","async":true}]
5:["$","$L6",null,{"children":["$","$7",null,{"name":"Next.MetadataOutlet","children":"$@8"}]}]
8:null
